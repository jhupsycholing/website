Automatically generated by Mendeley Desktop 1.17.10
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{JosephKing,
abstract = {Are syntactic categories like ​noun​and ​verb​categories of stems, such that the noun and verb versions of ambiguous stems like ​hammer​are distinct, though related, lexical items, or are syntactic categories carried by affixes attached to uncategorized roots, such that noun and verb versions of ambiguous stems are derived forms built on a single root? This paper addresses the representational question posed by syntactic categories by examining the processing of category ambiguous words. If syntactic categories are in fact categories of stems, category ambiguity should yield processing uncertainty parallel to that engendered by other forms of lexical ambiguity, such as homophony. On the other hand, if syntactic categories result from affixation, category ambiguity should yield processing uncertainty parallel to that engendered by syntactic uncertainty, at least if morphological structure reduces to syntactic structure as claimed by Distributed Morphology. A magnetoencephalographic (MEG) experiment exploiting a single word lexical decision task supports the syntactic over the lexical account of syntactic categories; category ambiguity parallels syntactic ambiguity rather than lexical ambiguity. The paper illustrates how neurolinguistic data can contribute to testing competing representational theories, but only when tight linking hypotheses are motivated connecting linguistic theory, cognitive processing, and neural responses.},
author = {{Joseph King}, Tal Linzen {\&} Alec Marantz},
journal = {Linguistic Inquiry},
keywords = {distributed morphology,meg,morphology,neurolinguistics,syntactic categories},
title = {{Syntactic categories as lexical features or syntactic heads: An MEG approach}},
url = {http://tallinzen.net/media/papers/king{\_}linzen{\_}marantz{\_}2015{\_}syntactic{\_}categories.pdf}
}
@inproceedings{EmileEnguehard,
abstract = {Recent work has explored the syntactic abilities of RNNs using the subject-verb agreement task, which diagnoses sensitivity to sentence structure. RNNs performed this task well in common cases, but faltered in complex sentences (Linzen et al., 2016). We test whether these errors are due to inherent limitations of the architecture or to the relatively indirect supervision provided by most agreement dependencies in a corpus. We trained a single RNN to perform both the agreement task and an additional task, either CCG supertagging or language modeling. Multitask training led to significantly lower error rates, in particular on complex sentences, suggesting that RNNs have the ability to evolve more sophisticated syntactic representations than shown before. We also show that easily available agreement training data can improve performance on other syntactic tasks, in particular when only a limited amount of training data is available for those tasks. The multi-task paradigm can also be leveraged to inject grammatical knowledge into language models.},
author = {{{\'{E}}mile Enguehard}, Yoav Goldberg {\&} Tal Linzen},
booktitle = {Proceedings of the SIGNLL Conference on Computational Natural Language Learning (CoNLL)},
title = {{Exploring the Syntactic Abilities of RNNs with Multi-task Learning}},
url = {http://tallinzen.net/media/papers/enguehard{\_}goldberg{\_}linzen{\_}2017{\_}conll.pdf}
}
@article{TalLinzen&YoheiOseki2015,
author = {{Tal Linzen {\&} Yohei Oseki}},
title = {{The reliability of acceptability judgments across languages}},
url = {http://tallinzen.net/media/papers/linzen{\_}oseki{\_}acceptability.pdf},
year = {2015}
}
@inproceedings{TalLinzen2017,
abstract = {Probabilistic prediction is a central process in language comprehension. Properties of probability distributions over predictions are often difficult to study in natural language. To obtain precise control over these distributions, we created artificial languages consisting of sequences of shapes. The languages were constructed to vary the uncertainty of the probability distribution over predictions as well as the probability of the predicted item. Participants were exposed to the languages in a self-paced presentation paradigm, which provides a measure of processing difficulty at each element of a sequence. There was a robust pattern of graded predictability: shapes were processed faster the more predictable they were, as in natural language. Processing times were also affected by the uncertainty (entropy) over predictions at the point at which those predictions were made; this effect was less consistent, however},
author = {{Tal Linzen}, Noam Siegelman {\&} Louisa Bogaerts},
booktitle = {Proceedings of the 39th Annual Conference of the Cognitive Science Society},
keywords = {Entropy,artificial,language,prediction,psycholinguistics,statistical learning},
mendeley-tags = {Entropy,artificial,language,prediction,psycholinguistics,statistical learning},
pages = {6},
title = {{Prediction and uncertainty in an artificial language}},
url = {http://tallinzen.net/media/papers/linzen{\_}siegelman{\_}bogaerts{\_}2017{\_}cogsci.pdf},
year = {2017}
}
@article{Gallagher2017,
abstract = {Speakers judge novel strings to be better potential words of their language if those strings consist of sound sequences that are attested in the language. These intuitions are often generalized to new sequences that share some properties with attested ones: participants exposed to an artificial language where all words start with the voiced stops [b] and [d] will prefer words that start with other voiced stops (e.g., [g]) to words that start with vowels or nasals. The current study tracks the evolution of generalization across sounds during the early stages of artificial language learning. In Experiments 1 and 2, participants received varying amounts of exposure to an artificial language. Learners rapidly generalized to new sounds: in fact, following short exposure to the language, attested patterns were not distinguished from unattested patterns that were similar in their phonological properties to the attested ones. Following additional exposure, participants showed an increasing preference for attested sounds, alongside sustained generalization to unattested ones. Finally, Experiment 3 tested whether participants can rapidly generalize to new sounds based on a single type of sound. We discuss the implications of our results for computational models of phonotactic learning.},
author = {Gallagher, Tal Linzen {\&} Gillian},
journal = {Laboratory Phonology},
title = {{Rapid generalization in phonotactic learning}},
url = {http://tallinzen.net/media/papers/linzen{\_}gallagher{\_}2017{\_}labphon.pdf},
year = {2017}
}
